{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LSTM\n",
    "- Multiple countries\n",
    "- Autoregressive training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import grad\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lunosoft\\AppData\\Local\\Temp\\ipykernel_13860\\1896199140.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_data[\"Real_date\"] = pd.to_datetime(country_data[\"Date_reported\"]) # save the real date for plotting\n",
      "C:\\Users\\Lunosoft\\AppData\\Local\\Temp\\ipykernel_13860\\1896199140.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_data[\"Date_reported\"] = pd.to_datetime(country_data[\"Date_reported\"])\n",
      "C:\\Users\\Lunosoft\\AppData\\Local\\Temp\\ipykernel_13860\\1896199140.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_data[\"Date_reported\"] = (country_data[\"Date_reported\"] - country_data[\"Date_reported\"].iloc[0]).dt.days\n",
      "C:\\Users\\Lunosoft\\AppData\\Local\\Temp\\ipykernel_13860\\1896199140.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_data[\"Real_date\"] = pd.to_datetime(country_data[\"Date_reported\"]) # save the real date for plotting\n",
      "C:\\Users\\Lunosoft\\AppData\\Local\\Temp\\ipykernel_13860\\1896199140.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_data[\"Date_reported\"] = pd.to_datetime(country_data[\"Date_reported\"])\n",
      "C:\\Users\\Lunosoft\\AppData\\Local\\Temp\\ipykernel_13860\\1896199140.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_data[\"Date_reported\"] = (country_data[\"Date_reported\"] - country_data[\"Date_reported\"].iloc[0]).dt.days\n",
      "C:\\Users\\Lunosoft\\AppData\\Local\\Temp\\ipykernel_13860\\1896199140.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_data[\"Real_date\"] = pd.to_datetime(country_data[\"Date_reported\"]) # save the real date for plotting\n",
      "C:\\Users\\Lunosoft\\AppData\\Local\\Temp\\ipykernel_13860\\1896199140.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_data[\"Date_reported\"] = pd.to_datetime(country_data[\"Date_reported\"])\n",
      "C:\\Users\\Lunosoft\\AppData\\Local\\Temp\\ipykernel_13860\\1896199140.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_data[\"Date_reported\"] = (country_data[\"Date_reported\"] - country_data[\"Date_reported\"].iloc[0]).dt.days\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "path = \"data/COVID_data.csv\"\n",
    "df = pd.read_csv(path)  # Replace with your file path\n",
    "\n",
    "country_waves = {\"Republic of Korea\": {1: [15, 123],\n",
    "                                   2: [206, 295],\n",
    "                                   3: [289, 436],\n",
    "                                   4: [533, 652], #좀 애매함\n",
    "                                   5: [736, 897],\n",
    "                                   6: [897, 1010],\n",
    "                                   7: [1010, 1164] #wave가 애매하게 2개임\n",
    "                                   },\n",
    "            \"China\": {1: [0, 74],\n",
    "                      2: [66, 119],\n",
    "                      3: [154, 266],\n",
    "                      4: [316, 413], #wave가 살짝 2개에 가까움\n",
    "                      5: [484, 561],\n",
    "                      6: [1065, 1119],\n",
    "                      },\n",
    "            \"United Kingdom of Great Britain and Northern Ireland\": {1: [52, 184],\n",
    "                                                                     2: [192, 486], #wave가 2개라서 아래의 3,4번에서 2개로 나눠도 봄.\n",
    "                                                                     3: [192, 330], #2번의 앞쪽 wave\n",
    "                                                                     4: [331, 486], #2번의 뒤쪽 wave\n",
    "                                                                     5: [772, 871],\n",
    "                                                                     6: [869, 983]\n",
    "                   }\n",
    "            }\n",
    "\n",
    "using_coutries = [\"Republic of Korea\", \"China\", \"United Kingdom of Great Britain and Northern Ireland\"]\n",
    "kind = 'New_cases' #[New_cases, Cumulative_cases, New_deaths, Cumulative_deaths]\n",
    "\n",
    "time_data = {\"Republic of Korea\": {}, \"China\": {}, \"United Kingdom of Great Britain and Northern Ireland\": {}}\n",
    "real_time_data = {\"Republic of Korea\": {}, \"China\": {}, \"United Kingdom of Great Britain and Northern Ireland\": {}}\n",
    "wave_data = {\"Republic of Korea\": {}, \"China\": {}, \"United Kingdom of Great Britain and Northern Ireland\": {}}\n",
    "\n",
    "for country in using_coutries:\n",
    "    country_data = df[df[\"Country\"] == country]\n",
    "    country_data[\"Real_date\"] = pd.to_datetime(country_data[\"Date_reported\"]) # save the real date for plotting\n",
    "    country_data[\"Date_reported\"] = pd.to_datetime(country_data[\"Date_reported\"])\n",
    "    country_data[\"Date_reported\"] = (country_data[\"Date_reported\"] - country_data[\"Date_reported\"].iloc[0]).dt.days\n",
    "    new_cases = country_data[kind].values\n",
    "    new_cases[new_cases < 1] = 1\n",
    "\n",
    "    for wave in country_waves[country]:\n",
    "        start, end = country_waves[country][wave]\n",
    "        time_data[country][wave] = country_data[\"Date_reported\"].values[start:end]\n",
    "        real_time_data[country][wave] = country_data[\"Real_date\"].values[start:end]\n",
    "        wave_data[country][wave] = new_cases[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the 7-number moving average\n",
    "def moving_average(data, window_size=7):\n",
    "    half_window = window_size // 2\n",
    "    smoothed = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        # Handle edge cases\n",
    "        start = max(0, i - half_window)\n",
    "        end = min(len(data), i + half_window + 1)\n",
    "        \n",
    "        # Calculate the average of the current window\n",
    "        smoothed.append(np.mean(data[start:end]))\n",
    "    \n",
    "    return smoothed\n",
    "\n",
    "data = {} # smoothed data\n",
    "\n",
    "for country in wave_data:\n",
    "    data[country] = {}\n",
    "    for wave in wave_data[country]:\n",
    "        data[country][wave] = moving_average(wave_data[country][wave])\n",
    "\n",
    "# which countries, which waves to use for training\n",
    "training_coutries = [\"Republic of Korea\", \"China\"]\n",
    "test_coutries = [\"United Kingdom of Great Britain and Northern Ireland\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the PINN model\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=64, num_layers=2, output_dim=1):\n",
    "        super(PINN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.layers = num_layers\n",
    "\n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(0)\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :]) # Shape: (batch_size, hidden_dim)\n",
    "        return out\n",
    "\n",
    "# Defining the loss functions\n",
    "def MSE_loss(y_true, y_pred):\n",
    "    return torch.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def SIR_loss(model, t, beta, gamma, mu):\n",
    "    t = t.requires_grad_(True)  # Enable gradient computation for time tensor\n",
    "\n",
    "    # Forward pass through the model\n",
    "    x = model(t)\n",
    "\n",
    "    # Compute gradients\n",
    "    dx_dt = torch.autograd.grad(\n",
    "        x, t, grad_outputs=torch.ones_like(x), create_graph=True\n",
    "    )[0]  # First derivative\n",
    "\n",
    "    # SIR model loss: dI/dt = beta * I - gamma * I\n",
    "    sir_loss = dx_dt + beta * torch.exp(x) - gamma * torch.exp(x)\n",
    "\n",
    "    # Return the squared loss\n",
    "    return torch.mean(sir_loss ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(data, test_start_point, predicted_values, date_ticks, country, epoch):\n",
    "    \"\"\"\n",
    "    Plot predictions and training results.\n",
    "    \"\"\"\n",
    "    # Ensure the save directory exists\n",
    "    #if not os.path.exists(save_path):\n",
    "    #    os.makedirs(save_path)\n",
    "\n",
    "    data = data.cpu().numpy()\n",
    "\n",
    "    predictions = np.append(np.array([None]*test_start_point), predicted_values)\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(18, 8))\n",
    "    plt.title(f\"{country}. Epoch: {epoch + 1}\")\n",
    "\n",
    "    # Training Data\n",
    "    ax1.plot(date_ticks, data, 'ro', markersize=8, label='Training data')\n",
    "\n",
    "    # Predicted values\n",
    "    ax1.plot(date_ticks, predictions, color=\"orange\", label=\"Predicted by PINN\")\n",
    "\n",
    "    # Format x-axis\n",
    "    ax1.set_xlabel(\"Date\")\n",
    "    ax1.set_ylabel(\"I(t)\", color=\"k\")\n",
    "    ax1.tick_params(axis='y', labelcolor=\"k\")\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax1.grid()\n",
    "\n",
    "    # Set date ticks\n",
    "    tick_labels = np.array(date_ticks[:len(data[::7])])\n",
    "    ax1.set_xticks(np.array(date_ticks[::7].flatten())) # 없어도 될 것 같음\n",
    "    ax1.set_xticklabels(tick_labels, rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, model, patience, display_step, sigma, sigma0, mu):\n",
    "        self.patience = patience\n",
    "        self.display_step = display_step\n",
    "        self.model = model\n",
    "        self.sigma = sigma\n",
    "        self.sigma0 = sigma0\n",
    "        self.mu = mu\n",
    "        \n",
    "        self.best_loss = np.inf\n",
    "        self.wait = 0\n",
    "\n",
    "        self.best_model = None\n",
    "        self.bests_weights = None\n",
    "        self.bestSigma = None\n",
    "        self.bestSigma0 = None\n",
    "        self.bestMu = None\n",
    "\n",
    "    def check_early_stopping(self, current_loss, epoch):\n",
    "        if current_loss < self.best_loss:\n",
    "            self.best_loss = current_loss.cpu().item() if torch.is_tensor(current_loss) else current_loss\n",
    "            self.wait = 0\n",
    "\n",
    "            self.best_model = self.model\n",
    "            self.best_weights = self.model.state_dict()\n",
    "            self.bestSigma = self.sigma\n",
    "            self.bestSigma0 = self.sigma0\n",
    "            self.bestMu = self.mu\n",
    "        else:\n",
    "            self.wait += 1\n",
    "        \n",
    "        if self.wait >= self.patience:\n",
    "            print(f\"Early stopping at epoch {epoch}.\")\n",
    "            self.model.load_state_dict(self.best_weights)\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lunosoft\\AppData\\Local\\Temp\\ipykernel_13860\\3791028123.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_t = torch.tensor(input_t_sequence, dtype=torch.float32).view(-1, 1).to(device)\n",
      "C:\\Users\\Lunosoft\\AppData\\Local\\Temp\\ipykernel_13860\\3791028123.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(data[i], dtype=torch.float32).view(-1, 1).to(device)\n"
     ]
    }
   ],
   "source": [
    "#autoregressive training version\n",
    "def train_autoregressive(model, optimizer, data, t_data, real_t, sigma, sigma0, mu, epochs, patience, display_step, date_ticks, country):\n",
    "    \"\"\"\n",
    "    Train the model using autoregressive learning.\n",
    "    \n",
    "    Parameters:\n",
    "        model: PINN model\n",
    "        optimizer: Optimizer\n",
    "        data: data for training\n",
    "        t_data: time sequence for SIR loss (1,2,3,...)\n",
    "        real_t: real time sequence for plotting (Date Time)\n",
    "        sigma, sigma0, mu: SIR model parameters\n",
    "        epochs: Total epochs\n",
    "        patience: Early stopping patience\n",
    "        display_step: Steps to visualize predictions\n",
    "        date_ticks: Time labels for plots\n",
    "        country: Country name for visualization\n",
    "    \"\"\"\n",
    "    early_stopping = EarlyStopping(model, patience, display_step, sigma, sigma0, mu)\n",
    "    losses = []\n",
    "\n",
    "    # Number of autoregressive steps (how far ahead to predict at each iteration)\n",
    "    start_point = 7  # Predict after week ahead\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        input_sequence = data[:start_point]\n",
    "        input_t_sequence = t_data[:start_point]\n",
    "\n",
    "        input_sequence = list(input_sequence)\n",
    "\n",
    "        for i in range(start_point, len(data)):\n",
    "            input_t = torch.tensor(input_t_sequence, dtype=torch.float32).view(-1, 1).to(device)\n",
    "            input_tensor = torch.tensor(input_sequence, dtype=torch.float32).view(-1, 1).to(device)\n",
    "            target = torch.tensor(data[i], dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "            with torch.backends.cudnn.flags(enabled=False):\n",
    "                # Forward pass\n",
    "                predicted = model(input_tensor)\n",
    "                mse_loss = MSE_loss(target, predicted)\n",
    "                sir_loss = SIR_loss(model, input_t, sigma, sigma0, mu)\n",
    "                # Combine losses\n",
    "                loss = mse_loss + sir_loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad() # Clear gradients\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            input_sequence.append(data[i])\n",
    "\n",
    "        avg_loss = total_loss / (len(data) - start_point)\n",
    "        losses.append(avg_loss)\n",
    "\n",
    "        test_start_point = int(len(data) / 3)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1}, MSE Loss = {mse_loss.item()}, SIR Loss = {sir_loss.item()}, Average Loss = {avg_loss}\")\n",
    "\n",
    "        if epoch % display_step == 0:\n",
    "            with torch.no_grad():\n",
    "                predicted_values = autoregressive_predict(model, data[:test_start_point], len(data) - test_start_point, delta_t=1)\n",
    "                # Ensure dimensions match for plotting\n",
    "                predicted_values = predicted_values[:len(data) - start_point]  # Slice to match y_data\n",
    "                plot_predictions(\n",
    "                    data,\n",
    "                    test_start_point,\n",
    "                    predicted_values=predicted_values,\n",
    "                    date_ticks=date_ticks,\n",
    "                    country=country,\n",
    "                    epoch=epoch,\n",
    "                )\n",
    "\n",
    "        if early_stopping.check_early_stopping(avg_loss, epoch):\n",
    "            break\n",
    "\n",
    "    return losses\n",
    "\n",
    "def autoregressive_predict(model, given_data, steps, delta_t):\n",
    "    \"\"\"\n",
    "    Predict future values in an autoregressive manner with multi-step outputs.\n",
    "    \n",
    "    Parameters:\n",
    "        model: Trained PINN model\n",
    "        data: data for prediction test\n",
    "        steps: Number of future steps to predict\n",
    "        delta_t: Step size for time\n",
    "    \n",
    "    Returns:\n",
    "        Predicted values (list)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    input_sequence = list(given_data)\n",
    "    predictions = torch.tensor([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(steps):\n",
    "            input_tensor = torch.tensor(input_sequence, dtype=torch.float32).view(-1, 1).to(device)\n",
    "            predicted = model(input_tensor).squeeze()\n",
    "            #predictions.append(predicted)\n",
    "            predictions = np.append(predictions, predicted.cpu().numpy())\n",
    "            input_sequence.append(predicted)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Initialize parameters\n",
    "sigma = torch.tensor([0.1], requires_grad=True).to(device)\n",
    "sigma0 = torch.tensor([0.1], requires_grad=True).to(device)\n",
    "mu = torch.tensor([0.1], requires_grad=True).to(device)\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "model = PINN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Train the model using autoregressive learning\n",
    "for country in training_coutries:\n",
    "    for wave in data[country]:\n",
    "        t_data = torch.tensor(time_data[country][wave], dtype=torch.float32).view(-1, 1).to(device)\n",
    "        y_data = torch.tensor(data[country][wave], dtype=torch.float32).view(-1, 1).to(device)\n",
    "        real_t = real_time_data[country][wave] # Real time data for plotting\n",
    "\n",
    "        t_train = t_data\n",
    "        y_train = y_data / max(y_data)  # Normalize data\n",
    "\n",
    "        losses = train_autoregressive(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            data=y_train,\n",
    "            t_data=t_train,\n",
    "            real_t=real_t,\n",
    "            sigma=sigma,\n",
    "            sigma0=sigma0,\n",
    "            mu=mu,\n",
    "            epochs=200,\n",
    "            patience=50,\n",
    "            display_step=100,\n",
    "            date_ticks=time_data[country][wave],\n",
    "            country=country\n",
    "        )\n",
    "\n",
    "        # Save the model for this wave\n",
    "        torch.save(model.state_dict(), f\"models/{country}_wave_{wave}_ar.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
